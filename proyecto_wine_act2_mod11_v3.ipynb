{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff430c99",
   "metadata": {},
   "source": [
    "# Proyecto Wine ‚Äî Notebook generado a partir de tu script modificado\n",
    "Este cuaderno contiene el c√≥digo actualizado con los cambios solicitados:\n",
    "- `penalty='none'` en lugar de `None` para `LogisticRegression`.\n",
    "- Importaci√≥n de `display` desde IPython si ejecutas fuera de notebook.\n",
    "- Inserci√≥n de `error_score=np.nan` en `RandomizedSearchCV` para mayor robustez.\n",
    "- Eliminaci√≥n de variable `y_test_bin` sin uso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b237498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Proyecto_Wine_Act2_Mod11_v2.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1zKFZfRF7AXHaHZhws6beOe8uVfqfZ1fL\n",
    "\n",
    "# Clasificaci√≥n de Vinos (Wine Dataset)\n",
    "\n",
    "**Curso:** Machine Learning ‚Äî Actividad 2 - Modulo 11  \n",
    "**Autor:** _John G√≥mez_  \n",
    "**Fecha:** _2025-10-01_\n",
    "\n",
    "---\n",
    "\n",
    "## Prop√≥sito del cuaderno\n",
    "Este notebook implementa un flujo completo de clasificaci√≥n supervisada sobre el dataset **Wine** (scikit-learn), que incluye:\n",
    "1) EDA avanzada con correlaciones y an√°lisis de outliers.  \n",
    "2) B√∫squeda automatizada de hiperpar√°metros (GridSearchCV/RandomizedSearchCV).  \n",
    "3) An√°lisis de importancia de caracter√≠sticas.  \n",
    "4) Documentaci√≥n completa de decisiones t√©cnicas.  \n",
    "5) Pipeline reproducible y listo para portafolio.\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# ==== Configuraci√≥n para Google Colab (opcional) ====\n",
    "# Ejecuta esta celda SOLO si est√°s en Colab o te faltan librer√≠as.\n",
    "# En tu entorno local, puedes comentar esta celda.\n",
    "try:\n",
    "    # Intenta importar el m√≥dulo google.colab para detectar si se est√° ejecutando en Colab.\n",
    "    import google.colab  # type: ignore\n",
    "    # Si estamos en Colab, instala las librer√≠as necesarias usando pip.\n",
    "    # -q suprime la salida detallada de pip.\n",
    "#     %pip install -q scikit-learn matplotlib pandas joblib seaborn\n",
    "except Exception:\n",
    "    # Si ocurre una excepci√≥n (no estamos en Colab o ya est√°n instaladas), no hacemos nada.\n",
    "    pass\n",
    "# Imprime un mensaje para confirmar que el entorno est√° listo.\n",
    "print(\"Entorno listo ‚úÖ\")\n",
    "\n",
    "# ==== 1. Importaci√≥n de librer√≠as ====\n",
    "import os # Para interactuar con el sistema operativo (crear directorios, etc.)\n",
    "import json # Para trabajar con datos en formato JSON (guardar metadatos)\n",
    "import joblib # Para guardar y cargar modelos de scikit-learn de forma eficiente\n",
    "import numpy as np # Para operaciones num√©ricas y arrays multidimensionales\n",
    "import pandas as pd # Para manipulaci√≥n y an√°lisis de datos (DataFrames)\n",
    "import matplotlib.pyplot as plt # Para crear visualizaciones est√°ticas\n",
    "import seaborn as sns # Basado en matplotlib, para visualizaciones estad√≠sticas m√°s atractivas\n",
    "from scipy import stats # Para funciones estad√≠sticas (ej: skewness)\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.datasets import load_wine # Carga el dataset de vinos\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV # Para dividir datos, validaci√≥n cruzada y b√∫squeda de hiperpar√°metros\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder # Para escalar caracter√≠sticas y codificar etiquetas\n",
    "from sklearn.pipeline import Pipeline # Para encadenar pasos de procesamiento de datos y modelado\n",
    "from sklearn.linear_model import LogisticRegression # Modelo de Regresi√≥n Log√≠stica\n",
    "from sklearn.ensemble import RandomForestClassifier # Modelo de Bosque Aleatorio\n",
    "from sklearn.svm import SVC # Modelo de M√°quinas de Vectores de Soporte\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, # M√©tricas de evaluaci√≥n: precisi√≥n, reporte completo, matriz de confusi√≥n\n",
    "    roc_auc_score, RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay # M√©tricas basadas en curvas ROC y Precision-Recall\n",
    ")\n",
    "from sklearn.inspection import permutation_importance # Para calcular la importancia de caracter√≠sticas por permutaci√≥n\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8') # Aplica un estilo visual a los gr√°ficos\n",
    "pd.set_option(\"display.max_columns\", 100) # Configura pandas para mostrar hasta 100 columnas\n",
    "pd.set_option(\"display.width\", 1000) # Configura el ancho de visualizaci√≥n de pandas\n",
    "sns.set_palette(\"husl\") # Establece la paleta de colores para seaborn\n",
    "\n",
    "# Confirma que todas las librer√≠as han sido importadas.\n",
    "print(\"‚úÖ Todas las librer√≠as importadas correctamente\")\n",
    "\n",
    "\"\"\"## 2. Carga de datos y EDA Avanzado\n",
    "An√°lisis exploratorio completo con visualizaciones mejoradas.\n",
    "\"\"\"\n",
    "\n",
    "# Carga del dataset\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Series(wine.target, name=\"class\")\n",
    "\n",
    "# Diccionario de traducci√≥n mejorado\n",
    "column_titles_es = {\n",
    "    \"alcohol\": \"Contenido de Alcohol\",\n",
    "    \"malic_acid\": \"√Åcido M√°lico\",\n",
    "    \"ash\": \"Ceniza\",\n",
    "    \"alcalinity_of_ash\": \"Alcalinidad de Ceniza\",\n",
    "    \"magnesium\": \"Magnesio\",\n",
    "    \"total_phenols\": \"Fenoles Totales\",\n",
    "    \"flavanoids\": \"Flavonoides\",\n",
    "    \"nonflavanoid_phenols\": \"Fenoles No Flavonoides\",\n",
    "    \"proanthocyanins\": \"Proantocianinas\",\n",
    "    \"color_intensity\": \"Intensidad del Color\",\n",
    "    \"hue\": \"Matiz\",\n",
    "    \"od280/od315_of_diluted_wines\": \"OD280/OD315 de Vinos Diluidos\",\n",
    "    \"proline\": \"Prolina\",\n",
    "}\n",
    "\n",
    "print(\"=== INFORMACI√ìN GENERAL DEL DATASET ===\")\n",
    "print(f\"üìä Dimensiones: {X.shape}\")\n",
    "print(f\"üéØ N√∫mero de clases: {len(np.unique(y))}\")\n",
    "print(f\"üî¢ Clases: {wine.target_names.tolist()}\")\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "print(\"\\n=== DISTRIBUCI√ìN DE CLASES ===\")\n",
    "class_dist = y.value_counts().sort_index()\n",
    "for cls, count in class_dist.items():\n",
    "    print(f\"Clase {cls} ({wine.target_names[cls]}): {count} muestras ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# An√°lisis de valores nulos\n",
    "print(\"\\n=== VALORES NULOS ===\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Estad√≠sticas descriptivas mejoradas\n",
    "print(\"\\n=== ESTAD√çSTICAS DESCRIPTIVAS ===\")\n",
    "stats_df = X.describe().T\n",
    "stats_df['cv'] = (stats_df['std'] / stats_df['mean']) * 100  # Coeficiente de variaci√≥n\n",
    "stats_df['skew'] = X.apply(stats.skew)\n",
    "display(stats_df.round(3))\n",
    "\n",
    "\"\"\"### 2.1 Visualizaciones Avanzadas de EDA\"\"\"\n",
    "\n",
    "# 1. Histogramas con distribuci√≥n por clase\n",
    "print(\"\\nüìà HISTOGRAMAS POR CARACTER√çSTICA Y CLASE\")\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(X.columns[:13]):\n",
    "    for cls in range(3):\n",
    "        axes[i].hist(X[y == cls][col], alpha=0.7, label=f'Clase {cls}', bins=15)\n",
    "    axes[i].set_title(f\"{column_titles_es.get(col, col)}\\n({col})\", fontsize=10)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].legend()\n",
    "\n",
    "# Eliminar ejes vac√≠os\n",
    "for i in range(13, 16):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Matriz de correlaci√≥n\n",
    "print(\"\\nüî• MATRIZ DE CORRELACI√ìN\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = X.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlaci√≥n entre Caracter√≠sticas', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Boxplots para detectar outliers\n",
    "print(\"\\nüì¶ BOXPLOTS POR CARACTER√çSTICA\")\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(X.columns[:13]):\n",
    "    X[col].plot(kind='box', ax=axes[i], vert=False)\n",
    "    axes[i].set_title(f\"{column_titles_es.get(col, col)}\", fontsize=10)\n",
    "    axes[i].set_xlabel('Valor')\n",
    "\n",
    "for i in range(13, 16):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Pairplot de caracter√≠sticas m√°s importantes\n",
    "print(\"\\nüîç PAIRPLOT DE CARACTER√çSTICAS PRINCIPALES\")\n",
    "features_for_pairplot = ['alcohol', 'malic_acid', 'ash', 'flavanoids', 'color_intensity', 'proline']\n",
    "sample_df = X[features_for_pairplot].copy()\n",
    "sample_df['class'] = y\n",
    "sample_df['class_name'] = sample_df['class'].map(lambda x: wine.target_names[x])\n",
    "\n",
    "sns.pairplot(sample_df, hue='class_name', diag_kind='hist')\n",
    "plt.suptitle('Pairplot de Caracter√≠sticas Seleccionadas por Clase', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"## 3. Partici√≥n Train/Test (Estratificada)\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"=== PARTICIONES DE DATOS ===\")\n",
    "print(f\"‚úÖ Conjunto de entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Conjunto de prueba: {X_test.shape[0]} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Proporci√≥n de clases en train: {np.bincount(y_train) / len(y_train)}\")\n",
    "print(f\"‚úÖ Proporci√≥n de clases en test: {np.bincount(y_test) / len(y_test)}\")\n",
    "\n",
    "\"\"\"## 4. Definici√≥n de Pipelines y B√∫squeda de Hiperpar√°metros\"\"\"\n",
    "\n",
    "# DECISIONES DE DISE√ëO:\n",
    "# 1. Estandarizaci√≥n en LogReg y SVM (sensibles a escala)\n",
    "# 2. RF sin escalado, mantenemos pipeline por consistencia\n",
    "# 3. Hiperpar√°metros base: LR(max_iter=1000), SVM(probability=True), RF(random_state)\n",
    "# 4. Validaci√≥n: StratifiedKFold con 5 splits\n",
    "pipelines = {\n",
    "    \"LogReg\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    \"SVM\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(probability=True, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"LogReg\": {\n",
    "        \"clf__C\": [0.1, 1, 10, 100],\n",
    "        \"clf__penalty\": [\"l2\", 'none'],   # <- usa None (sin comillas)\n",
    "        \"clf__solver\": [\"lbfgs\", \"newton-cg\"],  # compatibles con l2 y None\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"clf__n_estimators\": [100, 200, 300, 400],\n",
    "        \"clf__max_depth\": [None, 10, 20, 30],\n",
    "        \"clf__min_samples_split\": [2, 5, 10],\n",
    "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"clf__C\": [0.1, 1, 10, 100],\n",
    "        \"clf__gamma\": [\"scale\", \"auto\", 0.1, 0.01],\n",
    "        \"clf__kernel\": [\"rbf\", \"poly\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\"\"\"## 5. B√∫squeda de Hiperpar√°metros y Selecci√≥n del Mejor Modelo\"\"\"\n",
    "\n",
    "# Configura la validaci√≥n cruzada estratificada con 5 splits, mezclando los datos y usando una semilla para reproducibilidad.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Diccionarios para almacenar los mejores modelos encontrados y los resultados de la validaci√≥n cruzada.\n",
    "best_models = {}\n",
    "cv_results = {}\n",
    "\n",
    "# Define el n√∫mero de iteraciones (combinaciones de hiperpar√°metros) a probar para cada modelo en RandomizedSearchCV.\n",
    "# Se ajusta para Logistic Regression (16) y RandomForest/SVM (20), o 20 por defecto.\n",
    "n_iter_map = {\"LogReg\": 16, \"RandomForest\": 20, \"SVM\": 20}\n",
    "\n",
    "print(\"=== B√öSQUEDA DE HIPERPAR√ÅMETROS ===\")\n",
    "# Itera sobre cada nombre de pipeline definido anteriormente (\"LogReg\", \"RandomForest\", \"SVM\").\n",
    "for name in pipelines.keys():\n",
    "    print(f\"\\nüîç Optimizando {name}...\")\n",
    "    # Inicializa RandomizedSearchCV:\n",
    "    # - `pipelines[name]`: El pipeline a optimizar (modelo + pasos de preprocesamiento si existen).\n",
    "    # - `param_grids[name]`: El diccionario con los hiperpar√°metros y sus rangos a explorar para el modelo actual.\n",
    "    # - `cv=cv`: Usa la estrategia de validaci√≥n cruzada definida (StratifiedKFold).\n",
    "    # - `scoring='accuracy'`: La m√©trica a optimizar (precisi√≥n).\n",
    "    # - `n_iter=n_iter_map.get(name, 20)`: N√∫mero de combinaciones de hiperpar√°metros a probar aleatoriamente.\n",
    "    # - `random_state=42`: Semilla para el generador de n√∫meros aleatorios, asegura que la b√∫squeda sea reproducible.\n",
    "    # - `n_jobs=-1`: Utiliza todos los n√∫cleos disponibles del procesador para acelerar la b√∫squeda.\n",
    "    # - `error_score=\"raise\"`: Si ocurre un error al evaluar una combinaci√≥n, lanza una excepci√≥n en lugar de asignar NaN (opcional).\n",
    "    search = RandomizedSearchCV(\n",
    "        pipelines[name],\n",
    "        param_grids[name],\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_iter=n_iter_map.get(name, 20, error_score=np.nan),   # <- usa el mapa\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        error_score=\"raise\"  # opcional: si quieres que explote en lugar de NaN\n",
    "    )\n",
    "    # Ejecuta la b√∫squeda de hiperpar√°metros en el conjunto de entrenamiento.\n",
    "    search.fit(X_train, y_train)\n",
    "    # Almacena el mejor modelo encontrado (el que obtuvo la mejor puntuaci√≥n promedio en CV) en el diccionario `best_models`.\n",
    "    best_models[name] = search.best_estimator_\n",
    "    # Almacena los resultados relevantes de la b√∫squeda en el diccionario `cv_results`.\n",
    "    cv_results[name] = {\n",
    "        'best_score': float(search.best_score_), # La mejor puntuaci√≥n promedio de CV.\n",
    "        'best_params': search.best_params_, # Los hiperpar√°metros que lograron la mejor puntuaci√≥n.\n",
    "        'cv_mean': float(search.cv_results_['mean_test_score'].mean()), # Promedio de todas las puntuaciones de CV.\n",
    "        'cv_std': float(search.cv_results_['mean_test_score'].std()) # Desviaci√≥n est√°ndar de las puntuaciones de CV.\n",
    "    }\n",
    "    # Imprime los resultados de la b√∫squeda para el modelo actual.\n",
    "    print(f\"‚úÖ Mejor puntuaci√≥n: {search.best_score_:.4f}\")\n",
    "    print(f\"‚úÖ Mejores par√°metros: {search.best_params_}\")\n",
    "\n",
    "\n",
    "# Comparaci√≥n final de modelos:\n",
    "# Crea un DataFrame para resumir los mejores resultados de CV de cada modelo.\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': list(cv_results.keys()), # Nombres de los modelos.\n",
    "    'CV Score Mean': [cv_results[name]['best_score'] for name in cv_results.keys()], # La mejor puntuaci√≥n de CV para cada modelo.\n",
    "    'CV Score Std': [cv_results[name]['cv_std'] for name in cv_results.keys()], # La desviaci√≥n est√°ndar de las puntuaciones de CV.\n",
    "    'Best Params': [str(cv_results[name]['best_params'])[:80] + \"...\" for name in cv_results.keys()] # Los mejores par√°metros (truncados para mejor visualizaci√≥n).\n",
    "# Ordena el DataFrame por la mejor puntuaci√≥n de CV en orden descendente.\n",
    "}).sort_values('CV Score Mean', ascending=False)\n",
    "# Muestra el DataFrame resultante.\n",
    "results_df\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Modelo']\n",
    "best_pipeline = best_models[best_model_name]\n",
    "best_cv_score = cv_results[best_model_name]['best_score']\n",
    "best_params = cv_results[best_model_name]['best_params']\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO SELECCIONADO: {best_model_name}\")\n",
    "print(f\"üìà Mejor CV Score: {best_cv_score:.4f}\")\n",
    "print(f\"‚öôÔ∏è Par√°metros √≥ptimos: {best_params}\")\n",
    "\n",
    "\"\"\"## 6. Entrenamiento Final y Evaluaci√≥n Exhaustiva\"\"\"\n",
    "\n",
    "print(\"=== ENTRENAMIENTO FINAL Y EVALUACI√ìN ===\")\n",
    "# Entrena el mejor pipeline (seleccionado en el paso anterior) con el conjunto de entrenamiento completo.\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba.\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "# Realiza predicciones de probabilidad (si el modelo lo soporta).\n",
    "y_proba = best_pipeline.predict_proba(X_test)\n",
    "# Calcula la precisi√≥n del modelo en el conjunto de prueba.\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"üéØ Accuracy (Test): {acc:.4f}\")\n",
    "\n",
    "print(\"\\nüìã REPORTE DE CLASIFICACI√ìN:\")\n",
    "# Imprime el reporte de clasificaci√≥n completo (precisi√≥n, recall, f1-score) por clase.\n",
    "print(classification_report(y_test, y_pred, target_names=wine.target_names, digits=4))\n",
    "\n",
    "# Visualiza la matriz de confusi√≥n.\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Calcula la matriz de confusi√≥n.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Crea un objeto para mostrar la matriz de confusi√≥n.\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=wine.target_names)\n",
    "# Dibuja la matriz de confusi√≥n con un mapa de colores 'Blues' y valores enteros.\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(f'Matriz de Confusi√≥n - {best_model_name}', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualiza las curvas ROC por clase.\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Codifica las etiquetas de prueba a formato binario para las curvas ROC.\n",
    "# Itera sobre cada clase para trazar su curva ROC.\n",
    "for i, cls in enumerate(wine.target_names):\n",
    "    # Dibuja la curva ROC para la clase actual.\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        (y_test == i).astype(int), # Convierte las etiquetas a binario (1 si es la clase actual, 0 en caso contrario).\n",
    "        y_proba[:, i], # Probabilidades de la clase actual.\n",
    "        name=f\"Clase {cls}\", # Nombre de la curva.\n",
    "        plot_chance_level=(i==0) # Dibuja la l√≠nea de azar solo para la primera clase.\n",
    "    )\n",
    "plt.title(f'Curvas ROC por Clase - {best_model_name}', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcula el √°rea bajo la curva ROC (AUC) macro promedio (estrategia One-vs-Rest).\n",
    "auc_macro = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')\n",
    "print(f\"üìä ROC-AUC Macro (OVR): {auc_macro:.4f}\")\n",
    "\n",
    "\"\"\"## 7. An√°lisis de Importancia de Caracter√≠sticas\"\"\"\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS ===\")\n",
    "\n",
    "# Se verifica qu√© modelo fue seleccionado como el mejor para aplicar el m√©todo de importancia de caracter√≠sticas adecuado.\n",
    "if best_model_name == \"RandomForest\":\n",
    "    # Si el mejor modelo es RandomForest, se utiliza el atributo feature_importances_ del clasificador.\n",
    "    feature_importances = best_pipeline.named_steps['clf'].feature_importances_\n",
    "    # Se crea un DataFrame para mostrar las importancias junto con los nombres originales y traducidos de las caracter√≠sticas.\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Caracter√≠stica': X.columns,\n",
    "        'Importancia': feature_importances,\n",
    "        'Nombre_ES': [column_titles_es.get(col, col) for col in X.columns]\n",
    "    }).sort_values('Importancia', ascending=False) # Se ordena por importancia descendente.\n",
    "    display(importance_df) # Se muestra el DataFrame.\n",
    "    # Se crea un gr√°fico de barras para visualizar la importancia de las caracter√≠sticas.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df, x='Importancia', y='Caracter√≠stica')\n",
    "    plt.title('Importancia de Caracter√≠sticas - RandomForest', fontsize=14, pad=20)\n",
    "    plt.xlabel('Importancia (Gini)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif best_model_name == \"LogReg\":\n",
    "    # Si el mejor modelo es LogisticRegression, se utilizan los coeficientes del modelo.\n",
    "    # Se toma el valor absoluto promedio de los coeficientes a trav√©s de las clases para obtener una medida de importancia.\n",
    "    coefficients = best_pipeline.named_steps['clf'].coef_\n",
    "    avg_importance = np.mean(np.abs(coefficients), axis=0)\n",
    "    # Se crea un DataFrame similar al de RandomForest.\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Caracter√≠stica': X.columns,\n",
    "        'Importancia': avg_importance,\n",
    "        'Nombre_ES': [column_titles_es.get(col, col) for col in X.columns]\n",
    "    }).sort_values('Importancia', ascending=False) # Se ordena por importancia descendente.\n",
    "    display(importance_df) # Se muestra el DataFrame.\n",
    "    # Se crea un gr√°fico de barras para visualizar la importancia de las caracter√≠sticas.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df, x='Importancia', y='Caracter√≠stica')\n",
    "    plt.title('Importancia de Caracter√≠sticas - Regresi√≥n Log√≠stica', fontsize=14, pad=20)\n",
    "    plt.xlabel('Importancia (|coef| promedio)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # Si el mejor modelo es SVM (u otro que no tenga feature_importances_), se calcula la importancia por permutaci√≥n.\n",
    "    print(\"üîç Calculando importancia por permutaci√≥n...\")\n",
    "    # Se calcula la importancia por permutaci√≥n en el conjunto de prueba.\n",
    "    perm_importance = permutation_importance(\n",
    "        best_pipeline, X_test, y_test,\n",
    "        n_repeats=10, random_state=42, n_jobs=-1 # Se repite 10 veces y se usan todos los n√∫cleos disponibles.\n",
    "    )\n",
    "    # Se crea un DataFrame con la importancia promedio calculada.\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Caracter√≠stica': X.columns,\n",
    "        'Importancia': perm_importance.importances_mean,\n",
    "        'Nombre_ES': [column_titles_es.get(col, col) for col in X.columns]\n",
    "    }).sort_values('Importancia', ascending=False) # Se ordena por importancia descendente.\n",
    "    display(importance_df) # Se muestra el DataFrame.\n",
    "    # Se crea un gr√°fico de barras para visualizar la importancia de las caracter√≠sticas.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df, x='Importancia', y='Caracter√≠stica')\n",
    "    plt.title('Importancia de Caracter√≠sticas - Permutaci√≥n', fontsize=14, pad=20)\n",
    "    plt.xlabel('Disminuci√≥n promedio en accuracy') # Se especifica la m√©trica utilizada.\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"## 8. Persistencia del Modelo y Recursos\"\"\"\n",
    "\n",
    "# ==== 8. Persistencia del Modelo y Recursos ====\n",
    "\n",
    "# Crea el directorio 'model' si no existe para guardar los archivos.\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "# Define la ruta donde se guardar√° el mejor modelo, incluyendo el nombre del modelo y una versi√≥n.\n",
    "model_path = f\"model/best_model_{best_model_name}_v2.joblib\"\n",
    "# Guarda el objeto pipeline del mejor modelo en el archivo especificado usando joblib.\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "\n",
    "# Crea un diccionario con metadatos relevantes sobre el modelo entrenado.\n",
    "model_metadata = {\n",
    "    'model_name': best_model_name, # Nombre del mejor modelo.\n",
    "    'accuracy_test': float(acc), # Accuracy en el conjunto de prueba.\n",
    "    'auc_macro': float(auc_macro), # ROC-AUC macro promedio.\n",
    "    'best_parameters': best_params, # Par√°metros √≥ptimos encontrados.\n",
    "    'feature_importances': importance_df.to_dict('records'), # Importancia de caracter√≠sticas como lista de diccionarios.\n",
    "    'timestamp': pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"), # Fecha y hora de guardado.\n",
    "    'version': '2.0' # Versi√≥n del modelo/notebook.\n",
    "}\n",
    "\n",
    "# Guarda los metadatos en un archivo JSON.\n",
    "with open('model/model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2) # Usa indent=2 para un formato legible.\n",
    "\n",
    "# Confirma que el modelo y los metadatos han sido guardados.\n",
    "print(\"‚úÖ MODELO Y METADATOS GUARDADOS\")\n",
    "print(f\"üìÅ Modelo: {model_path}\")\n",
    "print(f\"üìÅ Metadatos: model/model_metadata.json\")\n",
    "\n",
    "# ==== 9. Ejemplo de Inferencia con el Modelo Guardado ====\n",
    "\n",
    "# Define una funci√≥n para realizar predicciones con un nuevo sample.\n",
    "# Toma el modelo entrenado y los datos del sample como entrada.\n",
    "def predict_new_sample(model, sample_data):\n",
    "    # Verifica si el modelo tiene el m√©todo predict_proba (para obtener probabilidades).\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        # Si lo tiene, predice las probabilidades y la clase.\n",
    "        proba = model.predict_proba(sample_data)\n",
    "        prediction = model.predict(sample_data)\n",
    "        return prediction, proba # Retorna la predicci√≥n y las probabilidades.\n",
    "    else:\n",
    "        # Si no tiene predict_proba, solo predice la clase.\n",
    "        prediction = model.predict(sample_data)\n",
    "        return prediction, None # Retorna solo la predicci√≥n.\n",
    "\n",
    "print(\"\\nüéØ EJEMPLO DE INFERENCIA:\")\n",
    "# Selecciona una muestra del conjunto de prueba para el ejemplo.\n",
    "sample_idx = 0 # √çndice de la muestra (la primera).\n",
    "sample = X_test.iloc[sample_idx:sample_idx+1] # Extrae la fila como DataFrame (necesario para el pipeline).\n",
    "true_class = y_test.iloc[sample_idx] # Obtiene la clase real de la muestra.\n",
    "# Realiza la predicci√≥n con el mejor pipeline.\n",
    "pred_class = best_pipeline.predict(sample)[0] # Obtiene la clase predicha.\n",
    "pred_proba = best_pipeline.predict_proba(sample)[0] # Obtiene las probabilidades predichas.\n",
    "\n",
    "# Imprime los resultados del ejemplo.\n",
    "print(f\"Muestra: {sample_idx}\")\n",
    "print(f\"Clase real: {true_class} ({wine.target_names[true_class]})\") # Muestra la clase real con su nombre.\n",
    "print(f\"Clase predicha: {pred_class} ({wine.target_names[pred_class]})\") # Muestra la clase predicha con su nombre.\n",
    "print(f\"Probabilidades: {np.round(pred_proba, 3)}\") # Muestra las probabilidades redondeadas.\n",
    "\n",
    "\"\"\"## 9. Plantilla de Revisi√≥n por Pares (Completar)\n",
    "\n",
    "**Nombre del/la revisor/a:** ___________________  \n",
    "**Fecha de revisi√≥n:** __________________\n",
    "\n",
    "**Fortalezas observadas:**\n",
    "- [ ] EDA avanzado con visualizaciones √∫tiles.\n",
    "- [ ] Uso de validaci√≥n cruzada y b√∫squeda de hiperpar√°metros.\n",
    "- [ ] Evaluaci√≥n exhaustiva con ROC-AUC y matriz de confusi√≥n.\n",
    "- [ ] Pipeline reproducible y documentaci√≥n clara.\n",
    "\n",
    "**√Åreas de mejora:**\n",
    "- [ ] Analizar impacto de normalizaci√≥n en cada modelo.\n",
    "- [ ] Comparar otras m√©tricas (macro F1, balanced accuracy).\n",
    "- [ ] Probar otros clasificadores (XGBoost/LightGBM si se permite).\n",
    "- [ ] Reducir dimensionalidad (PCA) y comparar.\n",
    "\n",
    "**Ajustes realizados por m√≠ (autor/a) despu√©s de la revisi√≥n:**\n",
    "-  \n",
    "-  \n",
    "-  \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
